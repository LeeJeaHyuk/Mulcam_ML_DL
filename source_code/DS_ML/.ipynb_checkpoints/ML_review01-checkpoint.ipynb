{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1eabdfc",
   "metadata": {},
   "source": [
    " 1) 머신러닝 프로세스 단계  \n",
    "\n",
    "        인스턴스화    ->   fit  -> Predict / transform \n",
    "       [estimator]  \n",
    "\n",
    "[1] estimator \n",
    " - estimator : 학습 데이터 기반에 모델을 적합시키고  새로운 데이터의 어떤 특성을\n",
    "    추론할 수 있는 객체를 말한다.  \n",
    "\n",
    "-  머신러닝에서 말하는 알고리즘은 estimator  객체(class)로 구현되어 있다.  \n",
    "\n",
    "-  검증(모델성능)  cross_val_score  함수 또는 하이퍼 파라미터를 튜닝하는  값들로 이루어져 있다.  \n",
    "  (  파라미터 : 함수가 가진 매개 인자  print(3)  / 하이퍼 파라미터 _ 알고리즘을 튜닝하는 값) \n",
    "    LinearRegression(*, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False)\n",
    "    GridSearchCV(Estimator(), ...).----> 하이퍼 파라미터제공한다. \n",
    "\n",
    " [2] fit  \n",
    "  -  estimator로 생성된 객체를 실행한다  또는 학습시킨다.  \n",
    "  -  지도 학습  = 학습 데이터  + 라벨데이터  /  비지도 학습  = 학습 데이터 \n",
    "  -  지도학습일 경우 estimators는 학습데이터로 부터 새로운 데이터를 예측하는 방법으로 학습된다.  \n",
    "            ex) model.fit(X_train, y_train) \n",
    " [3]Predict\n",
    "  - estimator를 사용하는 단계 \n",
    "  - 입력데이터에 대한 모델의 예측 결과를 리턴\n",
    "    ex) model.fit(X_train, y_train) \n",
    "        y_pred  = model.predict( X_test)  \n",
    "\n",
    " [4] transform  (ex : sklearn.preprocessing: 정규화 , 표준화,,,) \n",
    "    전처리(fit), 특징 , 특징추출, 차원축소  -> estimator  \n",
    "    특징 , 특징추출 (transform  )\n",
    "    ex) from sklearn.preprocessing  import  StandardScaler\n",
    "         #1. 전처리기 스케일링 작업을 하자.  \n",
    "           s=  StandardScaler()\n",
    "           s.fit(X_train)\n",
    "         X_train = s.tranform(X_train)     또는 fit과 transform을 한꺼번에 할 수 있다.            s.fit_transform(X_train)\n",
    "\n",
    "==================================\n",
    " 1) 예제 데이터 sklearn.datasets \n",
    "\n",
    "2) 피처 처리 sklearn.preprocessing 전처리 관련 기법 (원핫 인코딩, 정규화, 스케일링 등)\n",
    "                   sklearn.feature_selection 모델에 중요한 영향을 미치는 피처를 탐색 및 선택하는 기법\n",
    "                    sklearn.feature_extraction 원시 데이터로부터 피처를 추출하는 기능\n",
    "3) 차원 축소 sklearn.decomposition 차원 축소 관련 알고리즘 계열 (PCA, NMF, Truncated SVD 등)\n",
    "\n",
    "4) 검증, 하이퍼 파라미터 튜닝, 데이터 분리 :  sklearn.model_selection\n",
    "검증, 하이퍼 파라미터 튜닝, 데이터 분리 등\n",
    "(cross_validate, GridSearchCV, train_test _split,learning_curve 등)\n",
    "\n",
    "5)  모델 평가  : sklearn.metrics 모델의 성능을 측정 및 평가하는 기법\n",
    "                  (accuray, precision, recall, ROC curve 등)\n",
    "\n",
    "6) 기계학습 알고리즘 \n",
    "   sklearn.ensemble 앙상블 알고리즘 계열 (랜덤 포레스트, 에이다 부스트, 배깅 등)\n",
    "   sklearn.linear_model 선형 알고리즘 계열 (선형회귀, 로지스틱 회귀, SGD 등)\n",
    "   sklearn.naive_bayes 나이브 베이즈 알고리즘 계열(베르누이 NB, 가우시안 NB, 다항분포 NB 등)\n",
    "   sklearn.neighbors 최근접 이웃 알고리즘 계열 (K-NN 등)\n",
    "   sklearn.svm Support Vector Machine 계열 알고리즘\n",
    "   sklearn.tree 의사 결정 나무 계열 알고리즘\n",
    "   sklearn.cluster 비지도 학습(클러스터링) 알고리즘(KMeans, , DBSCAN 등)\n",
    "\n",
    "7) 유틸리티 : sklearn.pipeline 피처 처리 등의 변환과 기계학습 알고리즘 등을 연쇄적으로 실행하는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee26a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
